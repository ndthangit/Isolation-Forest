{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T16:08:34.760444Z",
     "start_time": "2024-11-10T16:08:30.860577Z"
    }
   },
   "id": "a241af747a5fd309",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_url = 'dataset-v2/part_1.csv'\n",
    "data = pd.read_csv(data_url, nrows=1000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T16:08:34.778045Z",
     "start_time": "2024-11-10T16:08:34.761620Z"
    }
   },
   "id": "2c8f9762f07a90",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     IPV4_SRC_ADDR  L4_SRC_PORT  IPV4_DST_ADDR  L4_DST_PORT  PROTOCOL  \\\n0  192.168.100.148        65389  192.168.100.7           80         6   \n1  192.168.100.148        11154  192.168.100.5           80         6   \n2     192.168.1.31        42062   192.168.1.79         1041         6   \n3     192.168.1.34        46849   192.168.1.79         9110         6   \n4     192.168.1.30        50360  192.168.1.152         1084         6   \n\n   L7_PROTO  IN_BYTES  IN_PKTS  OUT_BYTES  OUT_PKTS  ...  TCP_WIN_MAX_OUT  \\\n0       7.0       420        3          0         0  ...                0   \n1       7.0       280        2         40         1  ...                0   \n2       0.0        44        1         40         1  ...                0   \n3       0.0        44        1         40         1  ...                0   \n4       0.0        44        1         40         1  ...                0   \n\n   ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  DNS_TTL_ANSWER  \\\n0      35840             140             0               0               0   \n1          0               0             0               0               0   \n2          0               0             0               0               0   \n3          0               0             0               0               0   \n4          0               0             0               0               0   \n\n   FTP_COMMAND_RET_CODE  Label  Attack        Dataset  \n0                     0      1     DoS  NF-BoT-IoT-v2  \n1                     0      1     DoS  NF-BoT-IoT-v2  \n2                     0      0  Benign  NF-ToN-IoT-v2  \n3                     0      0  Benign  NF-ToN-IoT-v2  \n4                     0      0  Benign  NF-ToN-IoT-v2  \n\n[5 rows x 46 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>IPV4_SRC_ADDR</th>\n      <th>L4_SRC_PORT</th>\n      <th>IPV4_DST_ADDR</th>\n      <th>L4_DST_PORT</th>\n      <th>PROTOCOL</th>\n      <th>L7_PROTO</th>\n      <th>IN_BYTES</th>\n      <th>IN_PKTS</th>\n      <th>OUT_BYTES</th>\n      <th>OUT_PKTS</th>\n      <th>...</th>\n      <th>TCP_WIN_MAX_OUT</th>\n      <th>ICMP_TYPE</th>\n      <th>ICMP_IPV4_TYPE</th>\n      <th>DNS_QUERY_ID</th>\n      <th>DNS_QUERY_TYPE</th>\n      <th>DNS_TTL_ANSWER</th>\n      <th>FTP_COMMAND_RET_CODE</th>\n      <th>Label</th>\n      <th>Attack</th>\n      <th>Dataset</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>192.168.100.148</td>\n      <td>65389</td>\n      <td>192.168.100.7</td>\n      <td>80</td>\n      <td>6</td>\n      <td>7.0</td>\n      <td>420</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>35840</td>\n      <td>140</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>DoS</td>\n      <td>NF-BoT-IoT-v2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>192.168.100.148</td>\n      <td>11154</td>\n      <td>192.168.100.5</td>\n      <td>80</td>\n      <td>6</td>\n      <td>7.0</td>\n      <td>280</td>\n      <td>2</td>\n      <td>40</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>DoS</td>\n      <td>NF-BoT-IoT-v2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>192.168.1.31</td>\n      <td>42062</td>\n      <td>192.168.1.79</td>\n      <td>1041</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>44</td>\n      <td>1</td>\n      <td>40</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Benign</td>\n      <td>NF-ToN-IoT-v2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>192.168.1.34</td>\n      <td>46849</td>\n      <td>192.168.1.79</td>\n      <td>9110</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>44</td>\n      <td>1</td>\n      <td>40</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Benign</td>\n      <td>NF-ToN-IoT-v2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>192.168.1.30</td>\n      <td>50360</td>\n      <td>192.168.1.152</td>\n      <td>1084</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>44</td>\n      <td>1</td>\n      <td>40</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Benign</td>\n      <td>NF-ToN-IoT-v2</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 46 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T16:08:37.874863Z",
     "start_time": "2024-11-10T16:08:37.855922Z"
    }
   },
   "id": "9d5a8847945cda4d",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-10T13:55:23.473725Z",
     "start_time": "2024-11-10T13:55:06.657222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part_1.csv đã được tạo\n",
      "part_2.csv đã được tạo\n",
      "part_3.csv đã được tạo\n",
      "part_4.csv đã được tạo\n",
      "part_5.csv đã được tạo\n",
      "part_6.csv đã được tạo\n",
      "part_7.csv đã được tạo\n",
      "part_8.csv đã được tạo\n",
      "part_9.csv đã được tạo\n",
      "part_10.csv đã được tạo\n",
      "part_11.csv đã được tạo\n",
      "part_12.csv đã được tạo\n",
      "part_13.csv đã được tạo\n",
      "part_14.csv đã được tạo\n",
      "part_15.csv đã được tạo\n",
      "part_16.csv đã được tạo\n",
      "part_17.csv đã được tạo\n",
      "part_18.csv đã được tạo\n",
      "part_19.csv đã được tạo\n",
      "part_20.csv đã được tạo\n",
      "part_21.csv đã được tạo\n",
      "part_22.csv đã được tạo\n",
      "part_23.csv đã được tạo\n",
      "part_24.csv đã được tạo\n",
      "part_25.csv đã được tạo\n",
      "part_26.csv đã được tạo\n",
      "part_27.csv đã được tạo\n",
      "part_28.csv đã được tạo\n",
      "part_29.csv đã được tạo\n",
      "part_30.csv đã được tạo\n",
      "part_31.csv đã được tạo\n",
      "part_32.csv đã được tạo\n",
      "part_33.csv đã được tạo\n",
      "part_34.csv đã được tạo\n",
      "part_35.csv đã được tạo\n",
      "part_36.csv đã được tạo\n",
      "part_37.csv đã được tạo\n",
      "part_38.csv đã được tạo\n",
      "part_39.csv đã được tạo\n",
      "part_40.csv đã được tạo\n",
      "part_41.csv đã được tạo\n",
      "part_42.csv đã được tạo\n",
      "part_43.csv đã được tạo\n",
      "part_44.csv đã được tạo\n",
      "part_45.csv đã được tạo\n",
      "part_46.csv đã được tạo\n",
      "part_47.csv đã được tạo\n",
      "part_48.csv đã được tạo\n",
      "part_49.csv đã được tạo\n",
      "part_50.csv đã được tạo\n",
      "part_51.csv đã được tạo\n",
      "part_52.csv đã được tạo\n",
      "part_53.csv đã được tạo\n",
      "part_54.csv đã được tạo\n",
      "part_55.csv đã được tạo\n",
      "part_56.csv đã được tạo\n",
      "part_57.csv đã được tạo\n",
      "part_58.csv đã được tạo\n",
      "part_59.csv đã được tạo\n",
      "part_60.csv đã được tạo\n",
      "part_61.csv đã được tạo\n",
      "part_62.csv đã được tạo\n",
      "part_63.csv đã được tạo\n",
      "part_64.csv đã được tạo\n",
      "part_65.csv đã được tạo\n",
      "part_66.csv đã được tạo\n",
      "part_67.csv đã được tạo\n",
      "part_68.csv đã được tạo\n",
      "part_69.csv đã được tạo\n",
      "part_70.csv đã được tạo\n",
      "part_71.csv đã được tạo\n",
      "part_72.csv đã được tạo\n",
      "part_73.csv đã được tạo\n",
      "part_74.csv đã được tạo\n",
      "part_75.csv đã được tạo\n",
      "part_76.csv đã được tạo\n",
      "part_77.csv đã được tạo\n",
      "part_78.csv đã được tạo\n",
      "part_79.csv đã được tạo\n",
      "part_80.csv đã được tạo\n",
      "part_81.csv đã được tạo\n",
      "part_82.csv đã được tạo\n",
      "part_83.csv đã được tạo\n",
      "part_84.csv đã được tạo\n",
      "part_85.csv đã được tạo\n",
      "part_86.csv đã được tạo\n",
      "part_87.csv đã được tạo\n",
      "part_88.csv đã được tạo\n",
      "part_89.csv đã được tạo\n",
      "part_90.csv đã được tạo\n",
      "part_91.csv đã được tạo\n",
      "part_92.csv đã được tạo\n",
      "part_93.csv đã được tạo\n",
      "part_94.csv đã được tạo\n",
      "part_95.csv đã được tạo\n",
      "part_96.csv đã được tạo\n",
      "part_97.csv đã được tạo\n",
      "part_98.csv đã được tạo\n",
      "part_99.csv đã được tạo\n",
      "part_100.csv đã được tạo\n",
      "part_101.csv đã được tạo\n",
      "part_102.csv đã được tạo\n",
      "part_103.csv đã được tạo\n",
      "part_104.csv đã được tạo\n",
      "part_105.csv đã được tạo\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Đường dẫn đến tệp CSV lớn\n",
    "large_csv_file = 'dataset/data/NF-UQ-NIDS-v2-converted.csv'\n",
    "\n",
    "# Kích thước mỗi phần (ví dụ: 100,000 dòng)\n",
    "chunksize = 1000000\n",
    "chunk_count = 1\n",
    "\n",
    "# Đọc và lưu từng phần với dòng tiêu đề\n",
    "for chunk in pd.read_csv(large_csv_file, chunksize=chunksize):\n",
    "    small_csv_file = f'part_{chunk_count}.csv'\n",
    "    \n",
    "    # Ghi phần vào file mới với dòng tiêu đề\n",
    "    chunk.to_csv(small_csv_file, index=False, header=True)\n",
    "    \n",
    "    print(f'{small_csv_file} đã được tạo')\n",
    "    chunk_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.83 GiB for an array with shape (38, 10000000) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 16\u001B[0m\n\u001B[0;32m     13\u001B[0m chunk_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Đọc và lưu từng phần với dòng tiêu đề vào thư mục chỉ định\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m \u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlarge_csv_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Đường dẫn tệp trong thư mục đích\u001B[39;49;00m\n\u001B[0;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43msmall_csv_file\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_folder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpart_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mchunk_count\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Lưu phần vào file mới với dòng tiêu đề\u001B[39;49;00m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1843\u001B[0m, in \u001B[0;36mTextFileReader.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1841\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n\u001B[0;32m   1842\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1843\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_chunk\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1844\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m   1845\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1985\u001B[0m, in \u001B[0;36mTextFileReader.get_chunk\u001B[1;34m(self, size)\u001B[0m\n\u001B[0;32m   1983\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[0;32m   1984\u001B[0m     size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnrows \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_currow)\n\u001B[1;32m-> 1985\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1968\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1965\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1966\u001B[0m         new_col_dict \u001B[38;5;241m=\u001B[39m col_dict\n\u001B[1;32m-> 1968\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1969\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnew_col_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1970\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1971\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1972\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43musing_copy_on_write\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1973\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1975\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_currow \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m new_rows\n\u001B[0;32m   1976\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    772\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_mgr(\n\u001B[0;32m    773\u001B[0m         data, axes\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m\"\u001B[39m: index, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: columns}, dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39mcopy\n\u001B[0;32m    774\u001B[0m     )\n\u001B[0;32m    776\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m    777\u001B[0m     \u001B[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001B[39;00m\n\u001B[1;32m--> 778\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[43mdict_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmanager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    779\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ma\u001B[38;5;241m.\u001B[39mMaskedArray):\n\u001B[0;32m    780\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mma\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mrecords\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001B[0m, in \u001B[0;36mdict_to_mgr\u001B[1;34m(data, index, columns, dtype, typ, copy)\u001B[0m\n\u001B[0;32m    499\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    500\u001B[0m         \u001B[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001B[39;00m\n\u001B[0;32m    501\u001B[0m         arrays \u001B[38;5;241m=\u001B[39m [x\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m arrays]\n\u001B[1;32m--> 503\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marrays_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconsolidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001B[0m, in \u001B[0;36marrays_to_mgr\u001B[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001B[0m\n\u001B[0;32m    149\u001B[0m axes \u001B[38;5;241m=\u001B[39m [columns, index]\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mblock\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcreate_block_manager_from_column_arrays\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[43m        \u001B[49m\u001B[43marrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconsolidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconsolidate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrefs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrefs\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m typ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2144\u001B[0m, in \u001B[0;36mcreate_block_manager_from_column_arrays\u001B[1;34m(arrays, axes, consolidate, refs)\u001B[0m\n\u001B[0;32m   2142\u001B[0m     raise_construction_error(\u001B[38;5;28mlen\u001B[39m(arrays), arrays[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mshape, axes, e)\n\u001B[0;32m   2143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m consolidate:\n\u001B[1;32m-> 2144\u001B[0m     \u001B[43mmgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_consolidate_inplace\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2145\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m mgr\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1788\u001B[0m, in \u001B[0;36mBlockManager._consolidate_inplace\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1782\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_consolidate_inplace\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1783\u001B[0m     \u001B[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001B[39;00m\n\u001B[0;32m   1784\u001B[0m     \u001B[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001B[39;00m\n\u001B[0;32m   1785\u001B[0m     \u001B[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001B[39;00m\n\u001B[0;32m   1786\u001B[0m     \u001B[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001B[39;00m\n\u001B[0;32m   1787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_consolidated():\n\u001B[1;32m-> 1788\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks \u001B[38;5;241m=\u001B[39m \u001B[43m_consolidate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblocks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1789\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_consolidated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1790\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_known_consolidated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2269\u001B[0m, in \u001B[0;36m_consolidate\u001B[1;34m(blocks)\u001B[0m\n\u001B[0;32m   2267\u001B[0m new_blocks: \u001B[38;5;28mlist\u001B[39m[Block] \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m   2268\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (_can_consolidate, dtype), group_blocks \u001B[38;5;129;01min\u001B[39;00m grouper:\n\u001B[1;32m-> 2269\u001B[0m     merged_blocks, _ \u001B[38;5;241m=\u001B[39m \u001B[43m_merge_blocks\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2270\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mgroup_blocks\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcan_consolidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_can_consolidate\u001B[49m\n\u001B[0;32m   2271\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2272\u001B[0m     new_blocks \u001B[38;5;241m=\u001B[39m extend_blocks(merged_blocks, new_blocks)\n\u001B[0;32m   2273\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m(new_blocks)\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2294\u001B[0m, in \u001B[0;36m_merge_blocks\u001B[1;34m(blocks, dtype, can_consolidate)\u001B[0m\n\u001B[0;32m   2287\u001B[0m new_values: ArrayLike\n\u001B[0;32m   2289\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(blocks[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdtype, np\u001B[38;5;241m.\u001B[39mdtype):\n\u001B[0;32m   2290\u001B[0m     \u001B[38;5;66;03m# error: List comprehension has incompatible type List[Union[ndarray,\u001B[39;00m\n\u001B[0;32m   2291\u001B[0m     \u001B[38;5;66;03m# ExtensionArray]]; expected List[Union[complex, generic,\u001B[39;00m\n\u001B[0;32m   2292\u001B[0m     \u001B[38;5;66;03m# Sequence[Union[int, float, complex, str, bytes, generic]],\u001B[39;00m\n\u001B[0;32m   2293\u001B[0m     \u001B[38;5;66;03m# Sequence[Sequence[Any]], SupportsArray]]\u001B[39;00m\n\u001B[1;32m-> 2294\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mblocks\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   2295\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2296\u001B[0m     bvals \u001B[38;5;241m=\u001B[39m [blk\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;28;01mfor\u001B[39;00m blk \u001B[38;5;129;01min\u001B[39;00m blocks]\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\numpy\\core\\shape_base.py:289\u001B[0m, in \u001B[0;36mvstack\u001B[1;34m(tup, dtype, casting)\u001B[0m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arrs, \u001B[38;5;28mlist\u001B[39m):\n\u001B[0;32m    288\u001B[0m     arrs \u001B[38;5;241m=\u001B[39m [arrs]\n\u001B[1;32m--> 289\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_nx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcasting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcasting\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 2.83 GiB for an array with shape (38, 10000000) and data type int64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Đường dẫn đến tệp CSV lớn\n",
    "large_csv_file = 'dataset/data/NF-UQ-NIDS-v2.csv'\n",
    "\n",
    "# Tạo thư mục mới để lưu các tệp nhỏ\n",
    "output_folder = 'dataset-v2'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Kích thước mỗi phần (ví dụ: 100,000 dòng mỗi phần)\n",
    "chunksize = 10000000\n",
    "chunk_count = 1\n",
    "\n",
    "# Đọc và lưu từng phần với dòng tiêu đề vào thư mục chỉ định\n",
    "for chunk in pd.read_csv(large_csv_file, chunksize=chunksize):\n",
    "    # Đường dẫn tệp trong thư mục đích\n",
    "    small_csv_file = os.path.join(output_folder, f'part_{chunk_count}.csv')\n",
    "    \n",
    "    # Lưu phần vào file mới với dòng tiêu đề\n",
    "    chunk.to_csv(small_csv_file, index=False, header=True)\n",
    "    \n",
    "    print(f'{small_csv_file} đã được tạo')\n",
    "    chunk_count += 1\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-10T13:59:52.270098Z",
     "start_time": "2024-11-10T13:59:11.727436Z"
    }
   },
   "id": "2083287e1b91fa66",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset-v2\\part_1.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_2.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_3.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_4.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_5.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_6.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_7.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_8.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_9.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_10.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_11.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_12.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_13.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_14.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_15.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_16.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_17.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_18.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_19.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_20.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_21.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_22.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_23.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_24.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_25.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_26.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_27.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_28.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_29.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_30.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_31.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_32.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_33.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_34.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_35.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_36.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_37.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_38.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_39.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_40.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_41.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_42.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_43.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_44.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_45.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_46.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_47.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_48.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_49.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_50.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_51.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_52.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_53.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_54.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_55.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_56.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_57.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_58.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_59.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_60.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_61.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_62.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_63.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_64.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_65.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_66.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_67.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_68.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_69.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_70.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_71.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_72.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_73.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_74.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_75.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_76.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_77.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_78.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_79.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_80.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_81.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_82.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_83.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_84.csv đã được tạo (khoảng 146.484375 MB)\n",
      "dataset-v2\\part_85.csv đã được tạo (khoảng 146.484375 MB)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Đường dẫn đến tệp CSV lớn\n",
    "large_csv_file = 'dataset/data/NF-UQ-NIDS-v2.csv'\n",
    "\n",
    "# Tạo thư mục mới để lưu các tệp nhỏ\n",
    "output_folder = 'dataset-v2'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Giới hạn dung lượng mỗi file nhỏ (150,000 KB)\n",
    "max_file_size = 150000 * 1024  # 150,000 KB in bytes\n",
    "chunk_count = 1\n",
    "\n",
    "with open(large_csv_file, mode='r', newline='', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    header = next(reader)  # Lấy dòng tiêu đề\n",
    "    \n",
    "    # Khởi tạo file nhỏ đầu tiên\n",
    "    output_file = os.path.join(output_folder, f'part_{chunk_count}.csv')\n",
    "    out_file = open(output_file, mode='w', newline='', encoding='utf-8')\n",
    "    writer = csv.writer(out_file)\n",
    "    writer.writerow(header)  # Ghi dòng tiêu đề\n",
    "    \n",
    "    for row in reader:\n",
    "        writer.writerow(row)\n",
    "        \n",
    "        # Kiểm tra kích thước file\n",
    "        if out_file.tell() >= max_file_size:\n",
    "            out_file.close()\n",
    "            print(f'{output_file} đã được tạo (khoảng {max_file_size / (1024 * 1024)} MB)')\n",
    "            \n",
    "            # Tạo file nhỏ tiếp theo\n",
    "            chunk_count += 1\n",
    "            output_file = os.path.join(output_folder, f'part_{chunk_count}.csv')\n",
    "            out_file = open(output_file, mode='w', newline='', encoding='utf-8')\n",
    "            writer = csv.writer(out_file)\n",
    "            writer.writerow(header)  # Ghi dòng tiêu đề vào file mới\n",
    "    \n",
    "    # Đóng file cuối cùng\n",
    "    out_file.close()\n",
    "    print(f'{output_file} đã được tạo')\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-11-10T16:34:08.548043Z"
    }
   },
   "id": "920006af2ea1b256",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
