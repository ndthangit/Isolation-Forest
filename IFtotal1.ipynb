{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-27T08:55:20.690967Z",
     "start_time": "2024-12-27T08:55:20.681162Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "training_start = 1\n",
    "training_end = 3\n",
    "\n",
    "test_start =4\n",
    "test_end =5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-27T07:35:23.015185Z",
     "start_time": "2024-12-27T07:35:23.010884Z"
    }
   },
   "id": "829aaf26f12671ed",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the mapping of attack types to integer keys\n",
    "attack_type_map = {\n",
    "    'Benign': 0,\n",
    "    'DoS': 1,\n",
    "    'scanning': 2,\n",
    "    'DDoS': 3,\n",
    "    'xss': 4,\n",
    "    'Bot': 5,\n",
    "    'Reconnaissance': 6,\n",
    "    'password': 7,\n",
    "    'Fuzzers': 8,\n",
    "    'injection': 9,\n",
    "    'Theft': 10,\n",
    "    'Brute Force': 11,\n",
    "    'Infilteration': 12,\n",
    "    'Exploits': 13,\n",
    "    'Generic': 14,\n",
    "    'Analysis': 15,\n",
    "    'Backdoor': 16,\n",
    "    'mitm': 17,\n",
    "    'Shellcode': 18,\n",
    "    'ransomware': 19,\n",
    "    'Worms': 20\n",
    "}\n",
    "\n",
    "drop_column={\n",
    "    'Dataset',\n",
    "    'IPV4_SRC_ADDR',\n",
    "    'IPV4_DST_ADDR',\n",
    "    'L7_PROTO',\n",
    "    'SRC_TO_DST_SECOND_BYTES',\n",
    "    'DST_TO_SRC_SECOND_BYTES',\n",
    "    'FTP_COMMAND_RET_CODE',\n",
    "\n",
    "}\n",
    "drop_purposed_column= {\n",
    "    'Label',\n",
    "    'Attack'\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-27T07:35:25.027264Z",
     "start_time": "2024-12-27T07:35:25.019539Z"
    }
   },
   "id": "3034ce381ff4c05",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset-v2/part_1.csv')\n",
    "dataset.drop(columns=drop_column, inplace=True)\n",
    "dataset.drop(columns=drop_purposed_column, inplace=True)\n",
    "# dataset['Attack'] = dataset['Attack'].map(attack_type_map)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-21T01:57:26.371171Z",
     "start_time": "2024-12-21T01:57:19.786629Z"
    }
   },
   "id": "4ceebdab3e36eccf",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 850145 entries, 0 to 850144\n",
      "Data columns (total 37 columns):\n",
      " #   Column                       Non-Null Count   Dtype\n",
      "---  ------                       --------------   -----\n",
      " 0   L4_SRC_PORT                  850145 non-null  int64\n",
      " 1   L4_DST_PORT                  850145 non-null  int64\n",
      " 2   PROTOCOL                     850145 non-null  int64\n",
      " 3   IN_BYTES                     850145 non-null  int64\n",
      " 4   IN_PKTS                      850145 non-null  int64\n",
      " 5   OUT_BYTES                    850145 non-null  int64\n",
      " 6   OUT_PKTS                     850145 non-null  int64\n",
      " 7   TCP_FLAGS                    850145 non-null  int64\n",
      " 8   CLIENT_TCP_FLAGS             850145 non-null  int64\n",
      " 9   SERVER_TCP_FLAGS             850145 non-null  int64\n",
      " 10  FLOW_DURATION_MILLISECONDS   850145 non-null  int64\n",
      " 11  DURATION_IN                  850145 non-null  int64\n",
      " 12  DURATION_OUT                 850145 non-null  int64\n",
      " 13  MIN_TTL                      850145 non-null  int64\n",
      " 14  MAX_TTL                      850145 non-null  int64\n",
      " 15  LONGEST_FLOW_PKT             850145 non-null  int64\n",
      " 16  SHORTEST_FLOW_PKT            850145 non-null  int64\n",
      " 17  MIN_IP_PKT_LEN               850145 non-null  int64\n",
      " 18  MAX_IP_PKT_LEN               850145 non-null  int64\n",
      " 19  RETRANSMITTED_IN_BYTES       850145 non-null  int64\n",
      " 20  RETRANSMITTED_IN_PKTS        850145 non-null  int64\n",
      " 21  RETRANSMITTED_OUT_BYTES      850145 non-null  int64\n",
      " 22  RETRANSMITTED_OUT_PKTS       850145 non-null  int64\n",
      " 23  SRC_TO_DST_AVG_THROUGHPUT    850145 non-null  int64\n",
      " 24  DST_TO_SRC_AVG_THROUGHPUT    850145 non-null  int64\n",
      " 25  NUM_PKTS_UP_TO_128_BYTES     850145 non-null  int64\n",
      " 26  NUM_PKTS_128_TO_256_BYTES    850145 non-null  int64\n",
      " 27  NUM_PKTS_256_TO_512_BYTES    850145 non-null  int64\n",
      " 28  NUM_PKTS_512_TO_1024_BYTES   850145 non-null  int64\n",
      " 29  NUM_PKTS_1024_TO_1514_BYTES  850145 non-null  int64\n",
      " 30  TCP_WIN_MAX_IN               850145 non-null  int64\n",
      " 31  TCP_WIN_MAX_OUT              850145 non-null  int64\n",
      " 32  ICMP_TYPE                    850145 non-null  int64\n",
      " 33  ICMP_IPV4_TYPE               850145 non-null  int64\n",
      " 34  DNS_QUERY_ID                 850145 non-null  int64\n",
      " 35  DNS_QUERY_TYPE               850145 non-null  int64\n",
      " 36  DNS_TTL_ANSWER               850145 non-null  int64\n",
      "dtypes: int64(37)\n",
      "memory usage: 240.0 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-21T01:57:26.525160Z",
     "start_time": "2024-12-21T01:57:26.376146Z"
    }
   },
   "id": "7b48432031fa9ebc",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "list_attributes = dataset.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-21T01:57:26.534018Z",
     "start_time": "2024-12-21T01:57:26.527655Z"
    }
   },
   "id": "f0954cb592154dd5",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['L4_SRC_PORT', 'L4_DST_PORT', 'PROTOCOL', 'IN_BYTES', 'IN_PKTS',\n",
      "       'OUT_BYTES', 'OUT_PKTS', 'TCP_FLAGS', 'CLIENT_TCP_FLAGS',\n",
      "       'SERVER_TCP_FLAGS', 'FLOW_DURATION_MILLISECONDS', 'DURATION_IN',\n",
      "       'DURATION_OUT', 'MIN_TTL', 'MAX_TTL', 'LONGEST_FLOW_PKT',\n",
      "       'SHORTEST_FLOW_PKT', 'MIN_IP_PKT_LEN', 'MAX_IP_PKT_LEN',\n",
      "       'RETRANSMITTED_IN_BYTES', 'RETRANSMITTED_IN_PKTS',\n",
      "       'RETRANSMITTED_OUT_BYTES', 'RETRANSMITTED_OUT_PKTS',\n",
      "       'SRC_TO_DST_AVG_THROUGHPUT', 'DST_TO_SRC_AVG_THROUGHPUT',\n",
      "       'NUM_PKTS_UP_TO_128_BYTES', 'NUM_PKTS_128_TO_256_BYTES',\n",
      "       'NUM_PKTS_256_TO_512_BYTES', 'NUM_PKTS_512_TO_1024_BYTES',\n",
      "       'NUM_PKTS_1024_TO_1514_BYTES', 'TCP_WIN_MAX_IN', 'TCP_WIN_MAX_OUT',\n",
      "       'ICMP_TYPE', 'ICMP_IPV4_TYPE', 'DNS_QUERY_ID', 'DNS_QUERY_TYPE',\n",
      "       'DNS_TTL_ANSWER'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(list_attributes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-21T01:57:26.548858Z",
     "start_time": "2024-12-21T01:57:26.534018Z"
    }
   },
   "id": "b4adf6dbce5261e6",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset.drop(columns= list_attributes[0], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-21T01:57:26.747263Z",
     "start_time": "2024-12-21T01:57:26.551906Z"
    }
   },
   "id": "28b7cafa4fa8a705",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 850145 entries, 0 to 850144\n",
      "Data columns (total 36 columns):\n",
      " #   Column                       Non-Null Count   Dtype\n",
      "---  ------                       --------------   -----\n",
      " 0   L4_DST_PORT                  850145 non-null  int64\n",
      " 1   PROTOCOL                     850145 non-null  int64\n",
      " 2   IN_BYTES                     850145 non-null  int64\n",
      " 3   IN_PKTS                      850145 non-null  int64\n",
      " 4   OUT_BYTES                    850145 non-null  int64\n",
      " 5   OUT_PKTS                     850145 non-null  int64\n",
      " 6   TCP_FLAGS                    850145 non-null  int64\n",
      " 7   CLIENT_TCP_FLAGS             850145 non-null  int64\n",
      " 8   SERVER_TCP_FLAGS             850145 non-null  int64\n",
      " 9   FLOW_DURATION_MILLISECONDS   850145 non-null  int64\n",
      " 10  DURATION_IN                  850145 non-null  int64\n",
      " 11  DURATION_OUT                 850145 non-null  int64\n",
      " 12  MIN_TTL                      850145 non-null  int64\n",
      " 13  MAX_TTL                      850145 non-null  int64\n",
      " 14  LONGEST_FLOW_PKT             850145 non-null  int64\n",
      " 15  SHORTEST_FLOW_PKT            850145 non-null  int64\n",
      " 16  MIN_IP_PKT_LEN               850145 non-null  int64\n",
      " 17  MAX_IP_PKT_LEN               850145 non-null  int64\n",
      " 18  RETRANSMITTED_IN_BYTES       850145 non-null  int64\n",
      " 19  RETRANSMITTED_IN_PKTS        850145 non-null  int64\n",
      " 20  RETRANSMITTED_OUT_BYTES      850145 non-null  int64\n",
      " 21  RETRANSMITTED_OUT_PKTS       850145 non-null  int64\n",
      " 22  SRC_TO_DST_AVG_THROUGHPUT    850145 non-null  int64\n",
      " 23  DST_TO_SRC_AVG_THROUGHPUT    850145 non-null  int64\n",
      " 24  NUM_PKTS_UP_TO_128_BYTES     850145 non-null  int64\n",
      " 25  NUM_PKTS_128_TO_256_BYTES    850145 non-null  int64\n",
      " 26  NUM_PKTS_256_TO_512_BYTES    850145 non-null  int64\n",
      " 27  NUM_PKTS_512_TO_1024_BYTES   850145 non-null  int64\n",
      " 28  NUM_PKTS_1024_TO_1514_BYTES  850145 non-null  int64\n",
      " 29  TCP_WIN_MAX_IN               850145 non-null  int64\n",
      " 30  TCP_WIN_MAX_OUT              850145 non-null  int64\n",
      " 31  ICMP_TYPE                    850145 non-null  int64\n",
      " 32  ICMP_IPV4_TYPE               850145 non-null  int64\n",
      " 33  DNS_QUERY_ID                 850145 non-null  int64\n",
      " 34  DNS_QUERY_TYPE               850145 non-null  int64\n",
      " 35  DNS_TTL_ANSWER               850145 non-null  int64\n",
      "dtypes: int64(36)\n",
      "memory usage: 233.5 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-21T01:57:26.877623Z",
     "start_time": "2024-12-21T01:57:26.750272Z"
    }
   },
   "id": "c60502041a80f94d",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.30654098 -0.74821467 -0.0077353  ... -0.3387917  -0.13934468\n",
      "  -0.00167769]\n",
      " [-0.30654098 -0.74821467 -0.00962603 ... -0.3387917  -0.13934468\n",
      "  -0.00167769]\n",
      " [-0.21684028 -0.74821467 -0.01281326 ... -0.3387917  -0.13934468\n",
      "  -0.00167769]\n",
      " ...\n",
      " [-0.30654098  1.19632187 -0.01151676 ... -0.3387917  -0.13934468\n",
      "  -0.00167769]\n",
      " [-0.30654098 -0.74821467 -0.00854561 ... -0.3387917  -0.13934468\n",
      "  -0.00167769]\n",
      " [-0.30654098 -0.74821467 -0.00634426 ... -0.3387917  -0.13934468\n",
      "  -0.00167769]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "data_normalized = scaler.fit_transform(dataset)\n",
    "print(data_normalized)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-21T01:57:27.916641Z",
     "start_time": "2024-12-21T01:57:26.901269Z"
    }
   },
   "id": "22ad3e1293544ff5",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4607d32b9203a353"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m data \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdataset-v2/part_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m num_type \u001B[38;5;241m=\u001B[39m Counter(data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAttack\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m----> 7\u001B[0m label_type\u001B[38;5;241m=\u001B[39m \u001B[43mCounter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mLabel\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m total_counts\u001B[38;5;241m.\u001B[39mupdate(num_type)\n\u001B[0;32m      9\u001B[0m label_count\u001B[38;5;241m.\u001B[39mupdate(label_type)\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\collections\\__init__.py:599\u001B[0m, in \u001B[0;36mCounter.__init__\u001B[1;34m(self, iterable, **kwds)\u001B[0m\n\u001B[0;32m    588\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m'''Create a new, empty Counter object.  And if given, count elements\u001B[39;00m\n\u001B[0;32m    589\u001B[0m \u001B[38;5;124;03mfrom an input iterable.  Or, initialize the count from another mapping\u001B[39;00m\n\u001B[0;32m    590\u001B[0m \u001B[38;5;124;03mof elements to their counts.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    596\u001B[0m \n\u001B[0;32m    597\u001B[0m \u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[0;32m    598\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[1;32m--> 599\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "total_counts = Counter()\n",
    "\n",
    "label_count= Counter()\n",
    "for i in range(1,90):\n",
    "    data = pd.read_csv(f'dataset-v2/part_{i}.csv')\n",
    "    num_type = Counter(data['Attack'])\n",
    "    label_type= Counter(data['Label'])\n",
    "    total_counts.update(num_type)\n",
    "    label_count.update(label_type)\n",
    "print(\"\\nTổng số lượng của mỗi phần tử trong tất cả các file:\", total_counts)\n",
    "print(\"\\nTổng số lượng của mỗi nhãn trong tất cả các file:\", label_count)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-13T09:38:00.304197Z",
     "start_time": "2024-12-13T09:34:14.600346Z"
    }
   },
   "id": "193c712e304a4d0c",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(total_counts.keys(), total_counts.values())\n",
    "plt.show()\n",
    "plt.savefig('total_counts.png')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-13T09:38:00.306363Z"
    }
   },
   "id": "8207386d0a270e78",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(label_count.keys(), label_count.values())\n",
    "plt.show()\n",
    "plt.savefig('label_count.png')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-13T09:38:00.308774Z"
    }
   },
   "id": "7a5d352ed63cf8ac",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "IsolationForest_model= IsolationForest()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-27T07:35:43.447878Z",
     "start_time": "2024-12-27T07:35:43.442867Z"
    }
   },
   "id": "7f51a9f93b71be3d",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_url =[f'dataset-v2/part_{i}.csv' for i in range(training_start,training_end)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-27T07:51:21.878263Z",
     "start_time": "2024-12-27T07:51:21.872220Z"
    }
   },
   "id": "9228369c0cbd6af6",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def pre_processing(data):\n",
    "    data.drop(columns=drop_column, inplace=True)\n",
    "    data.drop(columns=drop_purposed_column, inplace=True)\n",
    "    scaler = StandardScaler()\n",
    "    data_normalized = scaler.fit_transform(data)\n",
    "    return data_normalized\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-27T08:56:38.128874Z",
     "start_time": "2024-12-27T08:56:38.121277Z"
    }
   },
   "id": "206f3993eed0569e",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(processing_function):\n",
    "    prediction =[]\n",
    "    original_result=[]\n",
    "    \n",
    "    model = IsolationForest()\n",
    "    \n",
    "    for train_path in train_url:\n",
    "        data = pd.read_csv(train_path)\n",
    "        label = data['Label']\n",
    "    \n",
    "        attack = data['Attack']\n",
    "        data = processing_function(data)        \n",
    "        model.fit(data)\n",
    "        \n",
    "        y_pred = model.predict(data)\n",
    "        \n",
    "        prediction.append(y_pred)\n",
    "        original_result.append(label)\n",
    "    #convert to 1D array\n",
    "    prediction = np.concatenate(prediction)\n",
    "    original_result = np.concatenate(original_result)\n",
    "    acc = accuracy_score(original_result, prediction)\n",
    "    f1 = f1_score(original_result, prediction)\n",
    "    roc_auc = roc_auc_score(original_result, prediction)\n",
    "    cm = confusion_matrix(original_result, prediction)\n",
    "    \n",
    "    return acc, f1,roc_auc,cm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-27T08:56:39.862395Z",
     "start_time": "2024-12-27T08:56:39.854897Z"
    }
   },
   "id": "6988a2665d1309b0",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 246. MiB for an array with shape (38, 850236) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocessing_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_processing\u001B[49m\u001B[43m)\u001B[49m)\n",
      "Cell \u001B[1;32mIn[30], line 8\u001B[0m, in \u001B[0;36mtrain_model\u001B[1;34m(processing_function)\u001B[0m\n\u001B[0;32m      5\u001B[0m model \u001B[38;5;241m=\u001B[39m IsolationForest()\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train_path \u001B[38;5;129;01min\u001B[39;00m train_url:\n\u001B[1;32m----> 8\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m     label \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLabel\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     11\u001B[0m     attack \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAttack\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m    899\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    900\u001B[0m     dialect,\n\u001B[0;32m    901\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    908\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m    909\u001B[0m )\n\u001B[0;32m    910\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 912\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[0;32m    582\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[1;32m--> 583\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1721\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1718\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1719\u001B[0m         new_rows \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(index)\n\u001B[1;32m-> 1721\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcol_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1723\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_currow \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m new_rows\n\u001B[0;32m   1724\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\core\\frame.py:709\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    703\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_mgr(\n\u001B[0;32m    704\u001B[0m         data, axes\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m\"\u001B[39m: index, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: columns}, dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39mcopy\n\u001B[0;32m    705\u001B[0m     )\n\u001B[0;32m    707\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m    708\u001B[0m     \u001B[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001B[39;00m\n\u001B[1;32m--> 709\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m \u001B[43mdict_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmanager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    710\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ma\u001B[38;5;241m.\u001B[39mMaskedArray):\n\u001B[0;32m    711\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mma\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mrecords\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:481\u001B[0m, in \u001B[0;36mdict_to_mgr\u001B[1;34m(data, index, columns, dtype, typ, copy)\u001B[0m\n\u001B[0;32m    477\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    478\u001B[0m         \u001B[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001B[39;00m\n\u001B[0;32m    479\u001B[0m         arrays \u001B[38;5;241m=\u001B[39m [x\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m x \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m arrays]\n\u001B[1;32m--> 481\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marrays_to_mgr\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconsolidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:153\u001B[0m, in \u001B[0;36marrays_to_mgr\u001B[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001B[0m\n\u001B[0;32m    150\u001B[0m axes \u001B[38;5;241m=\u001B[39m [columns, index]\n\u001B[0;32m    152\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mblock\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 153\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcreate_block_manager_from_column_arrays\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[43marrays\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconsolidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconsolidate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrefs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrefs\u001B[49m\n\u001B[0;32m    155\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    156\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m typ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    157\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2142\u001B[0m, in \u001B[0;36mcreate_block_manager_from_column_arrays\u001B[1;34m(arrays, axes, consolidate, refs)\u001B[0m\n\u001B[0;32m   2140\u001B[0m     raise_construction_error(\u001B[38;5;28mlen\u001B[39m(arrays), arrays[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mshape, axes, e)\n\u001B[0;32m   2141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m consolidate:\n\u001B[1;32m-> 2142\u001B[0m     \u001B[43mmgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_consolidate_inplace\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m mgr\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1829\u001B[0m, in \u001B[0;36mBlockManager._consolidate_inplace\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1823\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_consolidate_inplace\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1824\u001B[0m     \u001B[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001B[39;00m\n\u001B[0;32m   1825\u001B[0m     \u001B[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001B[39;00m\n\u001B[0;32m   1826\u001B[0m     \u001B[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001B[39;00m\n\u001B[0;32m   1827\u001B[0m     \u001B[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001B[39;00m\n\u001B[0;32m   1828\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_consolidated():\n\u001B[1;32m-> 1829\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks \u001B[38;5;241m=\u001B[39m \u001B[43m_consolidate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblocks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1830\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_consolidated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1831\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_known_consolidated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2272\u001B[0m, in \u001B[0;36m_consolidate\u001B[1;34m(blocks)\u001B[0m\n\u001B[0;32m   2270\u001B[0m new_blocks: \u001B[38;5;28mlist\u001B[39m[Block] \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m   2271\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (_can_consolidate, dtype), group_blocks \u001B[38;5;129;01min\u001B[39;00m grouper:\n\u001B[1;32m-> 2272\u001B[0m     merged_blocks, _ \u001B[38;5;241m=\u001B[39m \u001B[43m_merge_blocks\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2273\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mgroup_blocks\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcan_consolidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_can_consolidate\u001B[49m\n\u001B[0;32m   2274\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2275\u001B[0m     new_blocks \u001B[38;5;241m=\u001B[39m extend_blocks(merged_blocks, new_blocks)\n\u001B[0;32m   2276\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m(new_blocks)\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pythonProject\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2304\u001B[0m, in \u001B[0;36m_merge_blocks\u001B[1;34m(blocks, dtype, can_consolidate)\u001B[0m\n\u001B[0;32m   2301\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m bvals2[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39m_concat_same_type(bvals2, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m   2303\u001B[0m argsort \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margsort(new_mgr_locs)\n\u001B[1;32m-> 2304\u001B[0m new_values \u001B[38;5;241m=\u001B[39m \u001B[43mnew_values\u001B[49m\u001B[43m[\u001B[49m\u001B[43margsort\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m   2305\u001B[0m new_mgr_locs \u001B[38;5;241m=\u001B[39m new_mgr_locs[argsort]\n\u001B[0;32m   2307\u001B[0m bp \u001B[38;5;241m=\u001B[39m BlockPlacement(new_mgr_locs)\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 246. MiB for an array with shape (38, 850236) and data type int64"
     ]
    }
   ],
   "source": [
    "print(train_model(processing_function=pre_processing))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-27T08:56:55.535191Z",
     "start_time": "2024-12-27T08:56:40.165870Z"
    }
   },
   "id": "d68214896c9651c",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prediction =[]\n",
    "original_result=[]\n",
    "\n",
    "for train_path in train_url:\n",
    "    data = pd.read_csv(train_path)\n",
    "    data.drop(columns=drop_column, inplace=True)\n",
    "    # test['Attack'] = test['Attack'].map(attack_type_map)\n",
    "    label = data['Label']\n",
    "    \n",
    "    attack = data['Attack']\n",
    "    # label.replace(1,-1, inplace=True)\n",
    "    label.replace(0,-1, inplace=True)\n",
    "    data.drop(columns=drop_purposed_column, inplace=True)\n",
    "    \n",
    "    IsolationForest_model.fit(data)\n",
    "    \n",
    "    y_pred = IsolationForest_model.predict(data)\n",
    "    \n",
    "    prediction.append(y_pred)\n",
    "    original_result.append(label)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-27T08:07:57.635038Z",
     "start_time": "2024-12-27T08:07:23.970464Z"
    }
   },
   "id": "982fd855f72742a8",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#convert to 1D array\n",
    "prediction = np.concatenate(prediction)\n",
    "original_result = np.concatenate(original_result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-27T08:07:57.702596Z",
     "start_time": "2024-12-27T08:07:57.635038Z"
    }
   },
   "id": "a5729f5d81e4ae42",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700381\n"
     ]
    }
   ],
   "source": [
    "print(len(original_result))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-27T08:07:57.719545Z",
     "start_time": "2024-12-27T08:07:57.704156Z"
    }
   },
   "id": "9146471f7dd68dab",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-27T08:07:57.735831Z",
     "start_time": "2024-12-27T08:07:57.725926Z"
    }
   },
   "id": "f0db1cbc8bb3bea3",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7117510722596877 0.8178973896172461 0.5811175222424654 [[ 109554  453250]\n",
      " [  36883 1100694]]\n"
     ]
    }
   ],
   "source": [
    "# from docx import Document\n",
    "\n",
    "# Calculate metrics\n",
    "acc = accuracy_score(original_result, prediction)\n",
    "f1 = f1_score(original_result, prediction)\n",
    "roc_auc = roc_auc_score(original_result, prediction)\n",
    "cm = confusion_matrix(original_result, prediction)\n",
    "print(acc,f1,roc_auc,cm);\n",
    "\n",
    "# Create a new Document\n",
    "# doc = Document()\n",
    "# \n",
    "# # Add a title\n",
    "# doc.add_heading('Model Evaluation Results', level=1)\n",
    "# \n",
    "# # Add accuracy\n",
    "# doc.add_heading('Accuracy', level=2)\n",
    "# doc.add_paragraph(f\"IF acc = {acc}\")\n",
    "# \n",
    "# # Add F1 score\n",
    "# doc.add_heading('F1 Score', level=2)\n",
    "# doc.add_paragraph(f\"-IF f1 = {f1}\")\n",
    "# \n",
    "# # Add ROC AUC\n",
    "# doc.add_heading('ROC AUC', level=2)\n",
    "# doc.add_paragraph(f\"-IF roc auc = {roc_auc}\")\n",
    "# \n",
    "# # Add confusion matrix\n",
    "# doc.add_heading('Confusion Matrix', level=2)\n",
    "# cm_text = '\\n'.join(['\\t'.join(map(str, row)) for row in cm])\n",
    "# doc.add_paragraph(cm_text)\n",
    "# \n",
    "# # Save the document\n",
    "# doc.save('model_evaluation_results.docx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-27T08:08:04.183864Z",
     "start_time": "2024-12-27T08:07:57.735831Z"
    }
   },
   "id": "a42e15c37256fa5f",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7291755383598288\n"
     ]
    }
   ],
   "source": [
    "print(acc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-21T02:01:56.500996Z",
     "start_time": "2024-12-21T02:01:56.494911Z"
    }
   },
   "id": "36b1085e0e2d7d4c",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "\n",
    "# Save the heatmap as a PNG file\n",
    "plt.savefig('confusion_matrix_heatmap.png')\n",
    "\n",
    "# Show the heatmap\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-12-13T09:38:00.327473Z"
    }
   },
   "id": "654a490a6780926"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# feature selection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a9640d9803a392b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T08:28:06.144929Z",
     "start_time": "2024-12-16T08:28:06.140881Z"
    }
   },
   "id": "ebe450d5d5cf4804",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_and_evaluate_feature_selection(n_component):\n",
    "    IsolationForest_evaluate_model = IsolationForest()\n",
    "    pca = None  # Để lưu PCA\n",
    "    scaler = None  # Để lưu StandardScaler\n",
    "    \n",
    "    def train_data(data):\n",
    "        nonlocal pca, scaler\n",
    "        # Xóa các cột không cần thiết\n",
    "        data.drop(columns=drop_column, inplace=True)\n",
    "        label = data['Label']\n",
    "        data.drop(columns=drop_purposed_column, inplace=True)\n",
    "        \n",
    "        # Áp dụng PCA\n",
    "        pca = PCA(n_components=n_component)  # Giữ 95% phương sai\n",
    "        data_reduced = pca.fit_transform(data)\n",
    "        \n",
    "        # Chuẩn hóa dữ liệu\n",
    "        scaler = StandardScaler()\n",
    "        data_normalized = scaler.fit_transform(data_reduced)\n",
    "        \n",
    "        # Chuyển đổi nhãn\n",
    "        label.replace(0, -1, inplace=True)\n",
    "        \n",
    "        # Huấn luyện Isolation Forest\n",
    "        IsolationForest_evaluate_model.fit(data_normalized)\n",
    "    \n",
    "    for train_path in train_url:\n",
    "        data = pd.read_csv(train_path)\n",
    "        train_data(data)\n",
    "    \n",
    "    prediction = []\n",
    "    original_result = []\n",
    "    \n",
    "    def test_data(test):\n",
    "        nonlocal pca, scaler\n",
    "        # Xóa các cột không cần thiết\n",
    "        test.drop(columns=drop_column, inplace=True)\n",
    "        label = test['Label']\n",
    "        label.replace(0, -1, inplace=True)\n",
    "        test.drop(columns=drop_purposed_column, inplace=True)\n",
    "        \n",
    "        # Áp dụng PCA và chuẩn hóa\n",
    "        test_reduced = pca.transform(test)  # Áp dụng PCA từ tập train\n",
    "        test_normalized = scaler.transform(test_reduced)  # Áp dụng scaler từ tập train\n",
    "        \n",
    "        # Dự đoán\n",
    "        y_pred = IsolationForest_evaluate_model.predict(test_normalized)\n",
    "        return y_pred, label\n",
    "    \n",
    "    for test_path in test_url:\n",
    "        test = pd.read_csv(test_path)\n",
    "        y_pred, label = test_data(test)\n",
    "        prediction.append(y_pred)\n",
    "        original_result.append(label)\n",
    "    \n",
    "    # Ghép kết quả\n",
    "    prediction = np.concatenate(prediction)\n",
    "    original_result = np.concatenate(original_result)\n",
    "    \n",
    "    # Đánh giá mô hình\n",
    "    acc = accuracy_score(original_result, prediction)\n",
    "    f1 = f1_score(original_result, prediction)\n",
    "    roc_auc = roc_auc_score(original_result, prediction)\n",
    "    cm = confusion_matrix(original_result, prediction)\n",
    "    \n",
    "    return acc, f1, roc_auc, cm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T08:29:09.157402Z",
     "start_time": "2024-12-16T08:29:09.147351Z"
    }
   },
   "id": "ae7eae853d12641c",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def train_and_evaluate_feature_selection_with_other_estimator(n_estimator,n_component):\n",
    "    IsolationForest_evaluate_model = IsolationForest(n_estimators=n_estimator)\n",
    "    pca = None  # Để lưu PCA\n",
    "    scaler = None  # Để lưu StandardScaler\n",
    "    \n",
    "    def train_data(data):\n",
    "        nonlocal pca, scaler\n",
    "        # Xóa các cột không cần thiết\n",
    "        data.drop(columns=drop_column, inplace=True)\n",
    "        label = data['Label']\n",
    "        data.drop(columns=drop_purposed_column, inplace=True)\n",
    "        \n",
    "        # Áp dụng PCA\n",
    "        pca = PCA(n_components=n_component)  # Giữ số thành phần mong muốn\n",
    "        data_reduced = pca.fit_transform(data)\n",
    "        \n",
    "        # Chuẩn hóa dữ liệu\n",
    "        scaler = StandardScaler()\n",
    "        data_normalized = scaler.fit_transform(data_reduced)\n",
    "        \n",
    "        # Chuyển đổi nhãn\n",
    "        label.replace(0, -1, inplace=True)\n",
    "        \n",
    "        # Huấn luyện Isolation Forest\n",
    "        IsolationForest_evaluate_model.fit(data_normalized)\n",
    "    \n",
    "    for train_path in train_url:\n",
    "        data = pd.read_csv(train_path)\n",
    "        train_data(data)\n",
    "    \n",
    "    prediction = []\n",
    "    original_result = []\n",
    "    \n",
    "    def test_data(test):\n",
    "        nonlocal pca, scaler\n",
    "        # Xóa các cột không cần thiết\n",
    "        test.drop(columns=drop_column, inplace=True)\n",
    "        label = test['Label']\n",
    "        label.replace(0, -1, inplace=True)\n",
    "        test.drop(columns=drop_purposed_column, inplace=True)\n",
    "        \n",
    "        # Áp dụng PCA và chuẩn hóa\n",
    "        test_reduced = pca.transform(test)  # Áp dụng PCA từ tập train\n",
    "        test_normalized = scaler.transform(test_reduced)  # Áp dụng scaler từ tập train\n",
    "        \n",
    "        # Dự đoán\n",
    "        y_pred = IsolationForest_evaluate_model.predict(test_normalized)\n",
    "        return y_pred, label\n",
    "    \n",
    "    for test_path in test_url:\n",
    "        test = pd.read_csv(test_path)\n",
    "        y_pred, label = test_data(test)\n",
    "        prediction.append(y_pred)\n",
    "        original_result.append(label)\n",
    "    \n",
    "    # Ghép kết quả\n",
    "    prediction = np.concatenate(prediction)\n",
    "    original_result = np.concatenate(original_result)\n",
    "    \n",
    "    # Đánh giá mô hình\n",
    "    acc = accuracy_score(original_result, prediction)\n",
    "    f1 = f1_score(original_result, prediction)\n",
    "    roc_auc = roc_auc_score(original_result, prediction)\n",
    "    cm = confusion_matrix(original_result, prediction)\n",
    "    \n",
    "    return acc, f1, roc_auc, cm\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T08:50:47.299492Z",
     "start_time": "2024-12-16T08:50:47.282173Z"
    }
   },
   "id": "4aa63cca0c4afedf",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_and_evaluate_feature_selection_with_other_estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m test:\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m estimator:\n\u001B[1;32m----> 5\u001B[0m         acc, f1, roc_auc, cm \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_evaluate_feature_selection_with_other_estimator\u001B[49m(j,i)\n\u001B[0;32m      6\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_component = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      7\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_estimator = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mj\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_and_evaluate_feature_selection_with_other_estimator' is not defined"
     ]
    }
   ],
   "source": [
    "test =[0.4]\n",
    "estimator=[1500]\n",
    "for i in test:\n",
    "    for j in estimator:\n",
    "        acc, f1, roc_auc, cm = train_and_evaluate_feature_selection_with_other_estimator(j,i)\n",
    "        print(f\"n_component = {i}\")\n",
    "        print(f\"n_estimator = {j}\")\n",
    "        print(f\"Accuracy: {acc}\")\n",
    "        print(f\"F1 Score: {f1}\")\n",
    "        print(f\"ROC AUC: {roc_auc}\")\n",
    "        print(f\"Confusion Matrix:\\n{cm}\")\n",
    "        print()\n",
    "        # doc = Document()\n",
    "        # doc.add_heading('Model Evaluation Results', level=1)\n",
    "        # doc.add_heading('Feature Selection', level=2)\n",
    "        # doc.add_heading('PCA', level=3)\n",
    "        # doc.add_paragraph(f\"PCA n_component = {i}\")\n",
    "        # doc.add_paragraph(f\"n_estimator = {j}\")\n",
    "        # doc.add_paragraph(f\"Accuracy: {acc}\")\n",
    "        # doc.add_paragraph(f\"F1 Score: {f1}\")\n",
    "        # doc.add_paragraph(f\"ROC AUC: {roc_auc}\")\n",
    "        # doc.add_paragraph(f\"Confusion Matrix:\\n{cm}\")\n",
    "        # doc.save(f'model_evaluation_results_fs{i}_estimator{j}.docx')\n",
    "    \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T15:08:41.312285Z",
     "start_time": "2024-12-16T15:08:40.853010Z"
    }
   },
   "id": "ca7c1a7b45b7325a",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3776d407e5c757b8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
